{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision import Vision\n",
    "from globalPlanning import GlobalPlanning\n",
    "from localPlanning import LocalPlanning\n",
    "from kalman import Kalman\n",
    "from plotter import Plotter\n",
    "from thymioControl import ThymioControl\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdmclient.notebook\n",
    "await tdmclient.notebook.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tdmclient.notebook.sync_var\n",
    "def motor_go(left,right):\n",
    "    global motor_left_target, motor_right_target\n",
    "    motor_left_target = left\n",
    "    motor_right_target = right\n",
    "    \n",
    "@tdmclient.notebook.sync_var\n",
    "def motor_stop():\n",
    "    global motor_left_target,motor_right_target\n",
    "    motor_left_target = 0\n",
    "    motor_right_target = 0\n",
    "    \n",
    "@tdmclient.notebook.sync_var\n",
    "def sensor_data():\n",
    "    global prox_horizontal\n",
    "    return prox_horizontal.copy()\n",
    "\n",
    "@tdmclient.notebook.sync_var\n",
    "def leds():\n",
    "    global leds_top, leds_bottom_left, leds_bottom_right, leds_temperature, leds_circle\n",
    "    leds_top = [0, 0, 0]\n",
    "    leds_bottom_left = [0, 0, 0]\n",
    "    leds_bottom_right = [0, 0, 0]\n",
    "    leds_temperature = [0, 0]\n",
    "    leds_circle = [0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         vision = Vision(target_height=20, fps=3, threshold=128)\n",
    "\n",
    "#         while True:\n",
    "#             vision.update()\n",
    "#             vision.display_matrix()\n",
    "#             vision.display_info()\n",
    "\n",
    "#             if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                 break\n",
    "#     finally:\n",
    "#         vision.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLOBAL PLANNING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to achieve a position with the robot. To make this happen, we will use the global navigation. It's the same principle than follow a GPS, we build a path that our thymio will follow. This path start from the position of the thymio, and ends at the position of our goal placed on our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main funcion to test the GlobalPlanning class\n",
    "# import numpy as np\n",
    "# globalPlanning = GlobalPlanning()\n",
    "# matrix = np.zeros((15, 15))\n",
    "# matrix[1:6, 6:9] = -1; matrix[11, 1] = -1\n",
    "# start = (1, 1)\n",
    "# goal = (10, 10)\n",
    "# if start == None:\n",
    "#     print(\"No start found\")\n",
    "# elif goal == None:\n",
    "#     print(\"No goal found\")\n",
    "# else:\n",
    "#     #path, matrix2 = globalPlanning.dijkstra(vision.get_matrix(), vision.get_start(), vision.get_goal)\n",
    "#     path, matrix2 = globalPlanning.dijkstra(matrix, start, goal)\n",
    "#     print(path)\n",
    "#     print(matrix2)\n",
    "#     plotter = Plotter()\n",
    "#     plotter.plot_map_given(matrix2, start, goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOCAL PLANNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the global navigation module has designed a path from the start position to the goal, the local planning module has to generate the movement commands for the robot in such a way that it will follow that path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important part in robot's navigation is the avoidance of unexpected obstacles that might be detecte while moving from the start position to the goal, following the global plan. The process of local planning consists of detecting the obstacles using the robots sensors and designing a more or less efficient plan to get around it, avoiding collisions, and get back on the predetermined global plan.\n",
    "\n",
    "The Thymio robot features 5 horizontal proximity sensors it its front part (see Thyimio cheat sheet snippet) that can be used to detect obstacles using infrared technology. The range of values that the sensors return is [0, 4300], ranging from nothing detected to something detected at minimum distance from the sensor, and the updates come at a frequency of 10Hz.\n",
    "![image.png](images/thymio_cheat_sheet1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs: horizontal proximity sensors values\n",
    "Outputs: translation and rotation values for the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "threshold = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FLITERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Role of the Kalman Filter in the Project\n",
    "\n",
    "The Kalman Filter is a mathematical tool used in this project to estimate the robot's position and orientation (state) while navigating toward a goal. The robot uses data from two sources: **odometry** (wheel speeds) for prediction and a **camera** for occasional updates. Since both these sources are noisy and prone to errors, the Kalman Filter combines their information to produce an accurate and smooth estimate of the robot’s state.\n",
    "\n",
    "\n",
    "#### **Nonlinear Motion Model**\n",
    "A differential-drive robot's motion is inherently nonlinear because its position $(x, y)$ and orientation $\\theta$ depend on trigonometric relationships. For example, its state evolves as (motion model):\n",
    "\n",
    "$$\n",
    "x_{t+1} = x_t + v \\cos(\\theta) \\Delta t, \\quad y_{t+1} = y_t + v \\sin(\\theta) \\Delta t, \\quad \\theta_{t+1} = \\theta_t + \\omega \\Delta t\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- $v$: Linear velocity (derived from wheel speeds).\n",
    "- $\\omega$: Angular velocity (based on differential wheel motion).\n",
    "- $\\Delta t$: Time step.\n",
    "\n",
    "The EKF linearizes these equations using the Jacobian of the motion model. In the **Kalman class**, the motion model is embedded in the matrix $\\mathbf{G}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusing Odometry and Camera Data\n",
    "\n",
    "Odometry (wheel encoder data) is prone to errors such as:\n",
    "\n",
    "- **Drift** over time, accumulating inaccuracies as the robot moves.\n",
    "- **Wheel slippage** and uneven terrain causing deviations from the true trajectory.\n",
    "\n",
    "The camera, while more accurate, provides intermittent data due to potential obstructions or missed detections. The EKF combines these two sources of data to provide a reliable state estimate:\n",
    "\n",
    "1. **Prediction Step**: This step uses the odometry data to predict the robot's next state. It always runs, regardless of whether camera data is available, ensuring continuity in state estimation. The prediction compensates for missing measurements and accounts for process noise.\n",
    "\n",
    "2. **Update Step**: This step completes the prediction using camera measurements when available. It refines the estimated state by fusing the relatively accurate camera data with the prediction. The update step only runs if the camera is not obstructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. How the Kalman Filter Works**\n",
    "\n",
    "#### **A. Prediction Step**\n",
    "\n",
    "Using the robot's last known state, wheel speeds, and time elapsed (Δt), the Kalman Filter predicts the robot's next state:\n",
    "\n",
    "$$\n",
    "\\mathbf{E}_{\\text{pred}} = \\mathbf{A} \\cdot \\mathbf{E} + \\mathbf{G} \\cdot \\mathbf{U}\n",
    "$$\n",
    "\n",
    "- **A**: State transition matrix (accounts for constant movement without changes).\n",
    "- **B**: Control matrix (maps wheel speeds to motion).\n",
    "- **U**: Control vector (wheel speeds).\n",
    "\n",
    "It also predicts the **uncertainty** in the state, denoted by the covariance matrix **P**:\n",
    "\n",
    "$$\n",
    "\\mathbf{P}_{\\text{pred}} = \\mathbf{A} \\cdot \\mathbf{P} \\cdot \\mathbf{A}^T + \\mathbf{R}\n",
    "$$\n",
    "\n",
    "- **Q**: Process noise covariance (uncertainty from wheel encoders).\n",
    "\n",
    "#### **B. Update Step**\n",
    "\n",
    "When the camera provides a measurement **Z**, the Kalman Filter updates the state and uncertainty:\n",
    "\n",
    "1. Compute the Kalman gain **K**, which determines how much weight to give to the measurement:\n",
    "\n",
    "$$\n",
    "\\mathbf{K} = \\mathbf{P}_{\\text{pred}} \\cdot \\mathbf{H}^T \\cdot \\left(\\mathbf{H} \\cdot \\mathbf{P}_{\\text{pred}} \\cdot \\mathbf{H}^T + \\mathbf{Q}\\right)^{-1}\n",
    "$$\n",
    "\n",
    "- **H**: Measurement matrix (maps state to camera readings).\n",
    "- **R**: Measurement noise covariance (uncertainty in camera data).\n",
    "\n",
    "2. Update the state using the measurement:\n",
    "\n",
    "$$\n",
    "\\mathbf{E}_{\\text{update}} = \\mathbf{E}_{\\text{pred}} + \\mathbf{K} \\cdot \\left(\\mathbf{Z} - \\mathbf{H} \\cdot \\mathbf{E}_{\\text{pred}}\\right)\n",
    "$$\n",
    "\n",
    "3. Update the uncertainty:\n",
    "\n",
    "$$\n",
    "\\mathbf{P}_{\\text{update}} = (\\mathbf{I} - \\mathbf{K} \\cdot \\mathbf{H}) \\cdot \\mathbf{P}_{\\text{pred}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Behavior in the Control Loop**\n",
    "\n",
    "1. **Prediction Always Happens**:\n",
    "    * The prediction step runs at every iteration using odometry.\n",
    "    * This ensures the robot always has an estimated position, even if the camera data is unavailable.\n",
    "\n",
    "2. **Update Happens When the Camera Sees the Robot**:\n",
    "    * If the camera detects the robot, the Kalman Filter corrects its prediction using the more accurate camera measurement.\n",
    "\n",
    "3. **Handling Obstructions**:\n",
    "    * If the camera is obstructed, the filter relies solely on the prediction step until the camera resumes detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOTION CONTROL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTROL LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trajectory = []\n",
    "y_trajectory = []\n",
    "kalman_positions = []\n",
    "\n",
    "# initialize objects\n",
    "globalPlanning = GlobalPlanning()\n",
    "localPlanning = LocalPlanning()\n",
    "filter = Kalman()\n",
    "thymio = ThymioControl()\n",
    "plotter = Plotter()\n",
    "\n",
    "dt = 0.15\n",
    "\n",
    "# create a Vision object\n",
    "image_path3 = \"images/IMG_7028.jpeg\"\n",
    "vision = Vision(fps=3,target_height=200, default_image_path=image_path3)\n",
    "\n",
    "iter = 1\n",
    "\n",
    "goal_pos = [0, 0]\n",
    "\n",
    "goal = False\n",
    "\n",
    "leds()\n",
    "\n",
    "while not goal:\n",
    "    vision.update_image(live=False)\n",
    "    position = vision.getStart()\n",
    "    angle = vision.getAngle()\n",
    "\n",
    "    if (iter == 1):\n",
    "        print(\"First iteration\")\n",
    "        print(\"Getting map and Thymio position from camera\")\n",
    "        vision.update_image()\n",
    "        map = vision.getMatrix()\n",
    "        thymio.set_pose(position.copy(), angle)\n",
    "\n",
    "        if (position is None):\n",
    "            print(\"Error: camera obstructed in the first iteration\")\n",
    "            exit()\n",
    "                  \n",
    "        print(\"Computing path\")\n",
    "        print(\"Map shape: \", map.shape)\n",
    "        goal_pos = vision.getGoal()\n",
    "        path = globalPlanning.dijkstra(map, position, goal_pos)\n",
    "        thymio.set_path(path)\n",
    "        plotter.set_map(map, position, goal_pos)\n",
    "        plotter.plot_path(thymio.get_path_cells())\n",
    "        print(\"Path: \", thymio.get_path_cells())\n",
    "        x_trajectory.append(position[0])\n",
    "        y_trajectory.append(position[1])\n",
    "        filter.initialize_position(thymio.get_position()[0], thymio.get_position()[1], angle)\n",
    "        filter.set_lastKalman_time()\n",
    "\n",
    "    # check if camera is obstructed\n",
    "    if position is not None:\n",
    "        thymio.update_pose(position, angle)\n",
    "        print(\"Camera not obstructed, getting position from camera\")\n",
    "        x_trajectory.append(float(position[0]))\n",
    "        y_trajectory.append(float(position[1]))\n",
    "        # camera measuerement that will then be used for the Kalman filter\n",
    "        measurement = np.array([thymio.get_position()[0], thymio.get_position()[1], angle])\n",
    "        filter.kalman_update(measurement)\n",
    "        print(\"Kalman update: \", filter.get_state())\n",
    "        \n",
    "        # check if the robot has been kidnapped\n",
    "        if thymio.amIKidnapped():\n",
    "            print(\"Kidnapping detected\")\n",
    "\n",
    "            # tmdclient function to stop the motors\n",
    "            motor_stop()\n",
    "\n",
    "            # update the map with new robot position\n",
    "            time.sleep(2)\n",
    "            vision.update_image()\n",
    "            map = vision.getMatrix()\n",
    "            position = vision.getStart()\n",
    "            angle = vision.getAngle()\n",
    "\n",
    "            # new path planning\n",
    "            path = globalPlanning.dijkstra(map, position, goal_pos)\n",
    "            thymio.set_path(path)\n",
    "            plotter.plot_path(thymio.get_path_cells())\n",
    "            x_trajectory.append(position[0])\n",
    "            y_trajectory.append(position[1])\n",
    "            filter.initialize_position(thymio.get_position()[0], thymio.get_position()[1], angle)\n",
    "            filter.set_lastKalman_time()\n",
    "\n",
    "        if vision.getGoal() != goal_pos:\n",
    "            print(\"Goal changed\")\n",
    "            goal_pos = vision.getGoal()\n",
    "            path = globalPlanning.dijkstra(map, position, goal_pos)\n",
    "            thymio.set_path(path)\n",
    "            plotter.plot_path(thymio.get_path_cells())\n",
    "    \n",
    "    else:\n",
    "        print(\"Camera obstructed\")\n",
    "\n",
    "    # get the state from the Kalman filter\n",
    "    # the result will depend on the mode of the filter\n",
    "    x, y, angle = filter.get_state()\n",
    "    kalman_position = [x, y]\n",
    "    kalman_positions.append(position)\n",
    "    print(\"Kalman position used: \", kalman_position)\n",
    "\n",
    "    # check if the robot is detecting an obstacle\n",
    "    # tmclient function to get the proximity sensors\n",
    "    prox = sensor_data()\n",
    "    if (localPlanning.is_local_planning(prox)):\n",
    "        # move with local planning until the robot is not back on the path\n",
    "        wl, wr = localPlanning.local_planning(prox)\n",
    "        v, w = thymio.inverseDifferentialDrive(wl, wr)\n",
    "    else:\n",
    "        # move with global planning\n",
    "        v, w, wl, wr, goal = thymio.move(kalman_position, angle)\n",
    "\n",
    "    # update the Kalman filter\n",
    "    filter.kalman_prediction(wl, wr)\n",
    "\n",
    "    # tmdclient function to move the motors\n",
    "    wl = int(wl)\n",
    "    wr = int(wr)\n",
    "\n",
    "    print(\"Kalman pos 0: \", kalman_position[0])\n",
    "    print(\"Kalman pos 1: \", kalman_position[1])\n",
    "    print(\"v, w \", v, w)\n",
    "    print(\"angle: \", angle)\n",
    "    print(\"New angle: \", (angle + w*dt) % (2 * math.pi))\n",
    "\n",
    "\n",
    "    print(\"Trajectory: \", x_trajectory, y_trajectory)\n",
    "    plotter.plot_trajectory(x_trajectory, y_trajectory)\n",
    "\n",
    "    motor_go(wl, wr)\n",
    "    \n",
    "    # sleep for a while\n",
    "    iter += 1\n",
    "    time.sleep(dt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
